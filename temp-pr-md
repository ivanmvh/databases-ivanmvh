# Vet clinic database: database performance audit

## Learning objectives
- Understand what can impact database performance.

### Estimated time: 1.5h

## Description
In this project we will have a chance to optimize some slow queries in our database.

### General requirements

- Make sure that we used correct [Gitflow](https://github.com/microverseinc/curriculum-transversal-skills/blob/main/git-github/articles/gitflow.md).
- Make sure that we documented our work [in a professional way](https://github.com/microverseinc/curriculum-transversal-skills/blob/main/documentation/articles/professional_repo_rules.md).

### Preparation (0.5h)

For this project we need special preparation. As the goal of this project is to solve some performance issue, first we need to introduce those issues.
In order to do that, we will populate our database with a significant number of data.

Please complete the following steps:

1. Make sure that we have our database set up with the schema and data from our previous projects.
    - If we transitioned from 1.0 and we haven't complete the entire Ruby+Databases module, _we do not have the database ready._ In that case, please use the [schema.sql](./images/schema.sql) to create tables and [data.sql](./images/data.sql) to populate tables with the initial data.
3. Run the following query to add an extra column to the owners table:
  ``` sql
  -- Add an email column to our owners table
  ALTER TABLE owners ADD COLUMN email VARCHAR(120);
  ```
3. Run the following statements to add data to our database (**executing them might take a few minutes**):
  ```sql

  -- This will add 3.594.280 visits considering we have 10 animals, 4 vets, and it will use around ~87.000 timestamps (~4min approx.)
  INSERT INTO visits (animal_id, vet_id, date_of_visit) SELECT * FROM (SELECT id FROM animals) animal_ids, (SELECT id FROM vets) vets_ids, generate_series('1980-01-01'::timestamp, '2021-01-01', '4 hours') visit_timestamp;

  -- This will add 2.500.000 owners with full_name = 'Owner <X>' and email = 'owner_<X>@email.com' (~2min approx.)
  insert into owners (full_name, email) select 'Owner ' || generate_series(1,2500000), 'owner_' || generate_series(1,2500000) || '@mail.com';
  ```
4 Depening on our machine speed, it might be enough or not. Check that by running `explain analyze SELECT COUNT(*) FROM visits where animal_id = 4`:
     - If we get `Execution time: X ms` and X >= 1000: that should be enough, we can continue to the project requirements.
     - If we get `Execution time: X ms` and X < 1000: please go back to point 3. and repeat until we get a value bigger than 1000ms.

### Project requirements (1h)

- Use `EXPLAIN ANALYZE` on the next queries to check what is happening. Take screenshots of them - they will be necessary later.
- Find a way to decrease the execution time of the first query. Look for hints in the previous lessons.
- Find a way to improve execution time of the other two queries.
- While we are making changes, check if they help by running `EXPLAIN ANALYZE`. Once we succeed, take a screenshot of the `EXPLAIN ANALYZE` result showing that time actually decreased.
- Any changes we made to our database schema should be added to the schema.sql file and commited in a new pull request.
- If we decide to commit any `INSERT INTO` queries - remember to add the to the data.sql file. It is important to keep only the queries that change the database structure in the schema.sql file.
- In our pull request description include screenshots with `EXPLAIN ANALYZE` results (before and after we improve the speed) for each of the 3 problematic queries.

- The following queries are taking too much time (**1 sec = 1000ms can be considered as too much time for database query**). Try them on our machine to confirm it:
  - `SELECT COUNT(*) FROM visits where animal_id = 4;`

  - `SELECT * FROM visits where vet_id = 2;`
  
  - `SELECT * FROM owners where email = 'owner_18327@mail.com';`


